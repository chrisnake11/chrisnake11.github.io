---
title: 常用函数介绍
published: 2024-08-09T11:22:41Z
description: '神经网络常用python、pytorch函数介绍'
image: ''
tags: ['Neural Network']
category: 'Neural Network'
draft: false
---

# python函数

## 文件处理

`os.path`：系统路径处理包

+ `os.path.join(string path1, string path2)`：将path1和path2使用"/"或"\"，进行拼接。
  + `os.path.join(base_dir, folder) if folder else data_dir`：如果folder存在，返回`os.path.join(base_dir, folder)`，否则返回`data_dir`
+ `os.path.dirname(file)`：获取file文件夹绝对路径。
+ `os.path.splittext(file)`：返回文件的 文件名,后缀


+ `makedirs(string path, exist_ok=True)`：在path目录创建文件夹。
  + `exist_ok=True`：防止报出异常。如果存在直接跳过文件。


+ `with open(string filename, string flag) as f:`：打开filename文件，flag用于控制读取和写入的权限。
+ `f.read(1048576)`：读取指定字节大小(1048576 Bytes)的数据

## 网络请求下载

`requests`：用于发起网络请求、下载数据等

+ `requests.get(string url, stream=True, verify=True)`
  + `stream`: 响应内容以streaming的形式进行下载，而不是一次性下载完，减少大文件下的内存占用
  + `verify`：验证服务器的SSL证书。默认为True

```python
'''
下载url文件到..\\data下，文件名为url最后一个字段。
'''
def download_data(url, stream=True, verify=True):
    fname = os.path.join("..\\data", url.split('/')[-1])
    r = requests.get(url, stream, verify)
    with open(fname, 'wb') as f:
        f.write(r.content)
    return fname
```

## 解压缩

`tarlib`, `ziplib`：tar,gz,zip解压缩格式的库

+ `fp = zipfile.ZipFile(fname, flag)`：返回zip压缩文件的指针
+ `fp = tarfile.open(fname, flag)`：返回tar压缩文件的指针
+ `fp.extractall(base_dir)`：解压缩文件到base_dir目录

```python
'''
解压缩.zip .tar .gz格式压缩包，到当前目录。
'''
def extract(fname, folder=None):
    base_dir = os.path.dirname(fname)
    data_dir, ext = os.path.splitext(fname)
    if ext == '.zip':
        fp = zipfile.ZipFile(fname, 'r')
    elif ext in ('.tar', '.gz'):
        fp = tarfile.open(fname, 'r')
    else:
        assert False, '只有zip和tar，gz文件可以被解压缩'
    fp.extractall(base_dir) # 解压到base_dir
    return os.path.join(base_dir, folder) if folder else data_dir
```

## 数据操作

+ `idx = slice(begin, end)`：创建一个从begin~end的切片对象，可以作为索引操作符的元素
  + `array[idx]`：表示在array上应用idx切片。
+ `list.append()`：给数据列表中添加数据。

## 哈希验证

`hashlib`：进行哈希验证的操作

+ `sha1 = hashlib.sha1()`：生成sha1的操作对象
  + `sha1.update(data)`：逐步添加data数据，构建哈希值。
  + `sha1.hexdigest()`：数据添加完成后，获取最终的SHA1哈希值，返回16进制字符串。

# pandas函数(

## 读写数据

`read_csv(data)`：读取csv文件，返回dataframe。
`to_csv(file_path)`：将dataframe转化为csv文件。

## 数据操作

+ `dataframe.iloc([ 0:4, [0,1,2,-2,-1] ])`：切片函数，参数为一个二元组，第一个元素为行的范围，第二行的元素为列的范围。
  + `0:4`：表示0~4行，左闭右开。
  + `[0,1,2,-2,-1]`：用列表表示指定的行、列。
+ `pd.concat(data_1, data_2)`：按照指定的axis连接两个dataframe。axis默认为0.
+ `dataframe.dtypes(params).index`：获取参数指定的列索引。
  + `dataframe.dtypes(params)`：返回Series类型数据，元素为参数指定的列的元素类型。
  + `Series.index`：返回每列的索引部分，
+ `dataframe.apply(lambda_expr, axis=0)`：对每一行数据应用lambda表达式。默认axis=0.
+ `pandas.get_dummies(dataframe, dummy_na=True)`：将离散变量使用one-hot编码。单个离散特征会扩展为多个0/1值的特征。
+ `dataframe.fillna(values)`：将NAN、NA等缺失值设置为value
  + `value`：value可以为某个特定数据，可以是dict，表示不同的特征填充不同的值。
+ `pandas.Series(dataframe, index)`：转化为一维数组。
  + index：指定dataframe的索引部分数据。


# pytorch函数


## 数据操作

+ `torch.clamp()`：将数据按照axis压缩。
+ `torch.cat([data_list], axis=0)`：按照指定的axis来拼接数据。

### 数据计算

+ `torch.sqrt()`：将计算张量的平方根，返回一个张量。

### tensor

+ `torch.tensor.item()`：返回1维tensor的数值。
+ `torch.tensor()`：将pandas数据转化为tensor数据类型。



## 模型构建

`nn`：Neural Network包，包含了神经网络常用的损失函数、模型。

+ `nn.MSELoss()`：均方误差损失函数
+ `nn.Sequential()`：创建一个神经网络序列模型容器
+ `nn.Linear(input_dim, output_dim)`：创建一个线性模型，指定输入和输出的维度。


## 训练

+ `loss().backward()`：对损失函数，进行反向梯度求导。
+ `tensor.detach()`：返回一个从计算图中脱离出来的tensor。
+ `nn.Sequential(data)`：data作为输入，返回模型的输出。

## 优化

`torch.optim`：包括多个默认的优化器

+ `optimizer.zero_grad()`：每一次迭代前，清空梯度。
+ `optimizer.stem()`：继续下一步迭代